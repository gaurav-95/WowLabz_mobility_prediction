{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9eb3949",
   "metadata": {},
   "source": [
    "Source: https://www.programmersought.com/article/45455885835/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21ac8752",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\Gaurav\\Downloads\\WowLabz\\WowLabz_mobility_prediction\\Dataset\"\n",
    "file = r\"\\go_track_trackspoints.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc0c4cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Gaurav\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "Number of samples: 18107, dimension: 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      " (18099, 6, 2)\n",
      "y\n",
      " (18099, 2)\n",
      "Train on 18099 samples\n",
      "Epoch 1/100\n",
      "18099/18099 [==============================] - 4s 207us/sample - loss: 0.0181 - acc: 0.9477\n",
      "Epoch 2/100\n",
      "18099/18099 [==============================] - 3s 188us/sample - loss: 0.0044 - acc: 0.9592\n",
      "Epoch 3/100\n",
      "18099/18099 [==============================] - 4s 195us/sample - loss: 0.0039 - acc: 0.9631\n",
      "Epoch 4/100\n",
      "18099/18099 [==============================] - 3s 190us/sample - loss: 0.0036 - acc: 0.9630\n",
      "Epoch 5/100\n",
      "18099/18099 [==============================] - 4s 199us/sample - loss: 0.0032 - acc: 0.9646\n",
      "Epoch 6/100\n",
      "18099/18099 [==============================] - 4s 196us/sample - loss: 0.0030 - acc: 0.9667\n",
      "Epoch 7/100\n",
      "18099/18099 [==============================] - 4s 201us/sample - loss: 0.0028 - acc: 0.9652\n",
      "Epoch 8/100\n",
      "18099/18099 [==============================] - 4s 199us/sample - loss: 0.0026 - acc: 0.9636\n",
      "Epoch 9/100\n",
      "18099/18099 [==============================] - 5s 263us/sample - loss: 0.0024 - acc: 0.9664\n",
      "Epoch 10/100\n",
      "18099/18099 [==============================] - 5s 297us/sample - loss: 0.0022 - acc: 0.9654\n",
      "Epoch 11/100\n",
      "18099/18099 [==============================] - 5s 256us/sample - loss: 0.0020 - acc: 0.9670\n",
      "Epoch 12/100\n",
      "18099/18099 [==============================] - 4s 208us/sample - loss: 0.0018 - acc: 0.9660\n",
      "Epoch 13/100\n",
      "18099/18099 [==============================] - 4s 211us/sample - loss: 0.0016 - acc: 0.9679\n",
      "Epoch 14/100\n",
      "18099/18099 [==============================] - 4s 208us/sample - loss: 0.0014 - acc: 0.9684\n",
      "Epoch 15/100\n",
      "18099/18099 [==============================] - 4s 208us/sample - loss: 0.0012 - acc: 0.9694\n",
      "Epoch 16/100\n",
      "18099/18099 [==============================] - 4s 208us/sample - loss: 0.0011 - acc: 0.9681\n",
      "Epoch 17/100\n",
      "18099/18099 [==============================] - 4s 209us/sample - loss: 9.8202e-04 - acc: 0.9698\n",
      "Epoch 18/100\n",
      "18099/18099 [==============================] - 4s 209us/sample - loss: 8.2983e-04 - acc: 0.9701\n",
      "Epoch 19/100\n",
      "18099/18099 [==============================] - 4s 204us/sample - loss: 7.1957e-04 - acc: 0.9704\n",
      "Epoch 20/100\n",
      "18099/18099 [==============================] - 4s 205us/sample - loss: 6.5692e-04 - acc: 0.9713\n",
      "Epoch 21/100\n",
      "18099/18099 [==============================] - 4s 208us/sample - loss: 5.9856e-04 - acc: 0.9728\n",
      "Epoch 22/100\n",
      "18099/18099 [==============================] - 4s 206us/sample - loss: 5.6605e-04 - acc: 0.9704\n",
      "Epoch 23/100\n",
      "18099/18099 [==============================] - 4s 205us/sample - loss: 4.9356e-04 - acc: 0.9719\n",
      "Epoch 24/100\n",
      "18099/18099 [==============================] - 4s 213us/sample - loss: 4.9232e-04 - acc: 0.9716\n",
      "Epoch 25/100\n",
      "18099/18099 [==============================] - 4s 205us/sample - loss: 4.7050e-04 - acc: 0.9720\n",
      "Epoch 26/100\n",
      "18099/18099 [==============================] - 4s 209us/sample - loss: 4.4515e-04 - acc: 0.9733\n",
      "Epoch 27/100\n",
      "18099/18099 [==============================] - 4s 207us/sample - loss: 4.2802e-04 - acc: 0.9729\n",
      "Epoch 28/100\n",
      "18099/18099 [==============================] - 4s 205us/sample - loss: 4.0433e-04 - acc: 0.9748\n",
      "Epoch 29/100\n",
      "18099/18099 [==============================] - 4s 205us/sample - loss: 3.8924e-04 - acc: 0.9726\n",
      "Epoch 30/100\n",
      "18099/18099 [==============================] - 4s 210us/sample - loss: 3.8992e-04 - acc: 0.9746\n",
      "Epoch 31/100\n",
      "18099/18099 [==============================] - 4s 205us/sample - loss: 3.9900e-04 - acc: 0.9735\n",
      "Epoch 32/100\n",
      "18099/18099 [==============================] - 4s 209us/sample - loss: 3.7531e-04 - acc: 0.9740\n",
      "Epoch 33/100\n",
      "18099/18099 [==============================] - 4s 204us/sample - loss: 3.7989e-04 - acc: 0.9740\n",
      "Epoch 34/100\n",
      "18099/18099 [==============================] - 4s 212us/sample - loss: 3.5583e-04 - acc: 0.9743\n",
      "Epoch 35/100\n",
      "18099/18099 [==============================] - 4s 206us/sample - loss: 3.7936e-04 - acc: 0.9740\n",
      "Epoch 36/100\n",
      "18099/18099 [==============================] - 4s 206us/sample - loss: 4.0424e-04 - acc: 0.9739\n",
      "Epoch 37/100\n",
      "18099/18099 [==============================] - 4s 206us/sample - loss: 3.5432e-04 - acc: 0.9718\n",
      "Epoch 38/100\n",
      "18099/18099 [==============================] - 4s 205us/sample - loss: 3.4750e-04 - acc: 0.9760\n",
      "Epoch 39/100\n",
      "18099/18099 [==============================] - 4s 206us/sample - loss: 3.4711e-04 - acc: 0.9739\n",
      "Epoch 40/100\n",
      "18099/18099 [==============================] - 4s 207us/sample - loss: 3.3219e-04 - acc: 0.9741\n",
      "Epoch 41/100\n",
      "18099/18099 [==============================] - 4s 204us/sample - loss: 3.3701e-04 - acc: 0.9745\n",
      "Epoch 42/100\n",
      "18099/18099 [==============================] - 4s 204us/sample - loss: 3.3666e-04 - acc: 0.9744\n",
      "Epoch 43/100\n",
      "18099/18099 [==============================] - 4s 211us/sample - loss: 3.4904e-04 - acc: 0.9730\n",
      "Epoch 44/100\n",
      "18099/18099 [==============================] - 4s 203us/sample - loss: 3.1671e-04 - acc: 0.9746\n",
      "Epoch 45/100\n",
      "18099/18099 [==============================] - 4s 203us/sample - loss: 3.4467e-04 - acc: 0.9745\n",
      "Epoch 46/100\n",
      "18099/18099 [==============================] - 4s 212us/sample - loss: 3.0617e-04 - acc: 0.9751\n",
      "Epoch 47/100\n",
      "18099/18099 [==============================] - 4s 231us/sample - loss: 3.1115e-04 - acc: 0.9760\n",
      "Epoch 48/100\n",
      "18099/18099 [==============================] - 4s 233us/sample - loss: 3.0153e-04 - acc: 0.9739\n",
      "Epoch 49/100\n",
      "18099/18099 [==============================] - 4s 204us/sample - loss: 3.0770e-04 - acc: 0.9760\n",
      "Epoch 50/100\n",
      "18099/18099 [==============================] - 4s 208us/sample - loss: 3.1256e-04 - acc: 0.9744\n",
      "Epoch 51/100\n",
      "18099/18099 [==============================] - 4s 232us/sample - loss: 3.0306e-04 - acc: 0.9758\n",
      "Epoch 52/100\n",
      "18099/18099 [==============================] - 5s 253us/sample - loss: 3.0866e-04 - acc: 0.9733\n",
      "Epoch 53/100\n",
      "18099/18099 [==============================] - 5s 267us/sample - loss: 3.1472e-04 - acc: 0.9759s - loss: 3.1680e-04 - acc: 0.9\n",
      "Epoch 54/100\n",
      "18099/18099 [==============================] - 5s 253us/sample - loss: 3.1928e-04 - acc: 0.9745\n",
      "Epoch 55/100\n",
      "18099/18099 [==============================] - 5s 268us/sample - loss: 3.0053e-04 - acc: 0.9756\n",
      "Epoch 56/100\n",
      "18099/18099 [==============================] - 4s 237us/sample - loss: 3.0510e-04 - acc: 0.9741\n",
      "Epoch 57/100\n",
      "18099/18099 [==============================] - 4s 236us/sample - loss: 3.0021e-04 - acc: 0.9762\n",
      "Epoch 58/100\n",
      "18099/18099 [==============================] - 4s 241us/sample - loss: 2.9770e-04 - acc: 0.9737\n",
      "Epoch 59/100\n",
      "18099/18099 [==============================] - 4s 246us/sample - loss: 2.9075e-04 - acc: 0.9749\n",
      "Epoch 60/100\n",
      "18099/18099 [==============================] - 5s 261us/sample - loss: 3.0342e-04 - acc: 0.9746\n",
      "Epoch 61/100\n",
      "18099/18099 [==============================] - 4s 247us/sample - loss: 3.2773e-04 - acc: 0.9735\n",
      "Epoch 62/100\n",
      "18099/18099 [==============================] - 5s 250us/sample - loss: 3.0633e-04 - acc: 0.9733\n",
      "Epoch 63/100\n",
      "18099/18099 [==============================] - 4s 235us/sample - loss: 3.3440e-04 - acc: 0.9747\n",
      "Epoch 64/100\n",
      "18099/18099 [==============================] - 4s 209us/sample - loss: 3.0924e-04 - acc: 0.9744\n",
      "Epoch 65/100\n",
      "18099/18099 [==============================] - 4s 214us/sample - loss: 3.0045e-04 - acc: 0.9766\n",
      "Epoch 66/100\n",
      "18099/18099 [==============================] - 4s 203us/sample - loss: 3.0305e-04 - acc: 0.9748\n",
      "Epoch 67/100\n",
      "18099/18099 [==============================] - 3s 191us/sample - loss: 2.9592e-04 - acc: 0.9760\n",
      "Epoch 68/100\n",
      "18099/18099 [==============================] - 3s 191us/sample - loss: 2.9376e-04 - acc: 0.9745\n",
      "Epoch 69/100\n",
      "18099/18099 [==============================] - 4s 195us/sample - loss: 3.0117e-04 - acc: 0.9770\n",
      "Epoch 70/100\n",
      "18099/18099 [==============================] - 3s 193us/sample - loss: 2.9596e-04 - acc: 0.9759\n",
      "Epoch 71/100\n",
      "18099/18099 [==============================] - 3s 191us/sample - loss: 3.0000e-04 - acc: 0.9756\n",
      "Epoch 72/100\n",
      "18099/18099 [==============================] - 3s 190us/sample - loss: 2.9429e-04 - acc: 0.9755\n",
      "Epoch 73/100\n",
      "18099/18099 [==============================] - 3s 189us/sample - loss: 3.0700e-04 - acc: 0.9761\n",
      "Epoch 74/100\n",
      "18099/18099 [==============================] - 3s 191us/sample - loss: 2.9698e-04 - acc: 0.9768\n",
      "Epoch 75/100\n",
      "18099/18099 [==============================] - 4s 194us/sample - loss: 2.9006e-04 - acc: 0.9732\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18099/18099 [==============================] - 3s 192us/sample - loss: 3.0258e-04 - acc: 0.9742\n",
      "Epoch 77/100\n",
      "18099/18099 [==============================] - 4s 194us/sample - loss: 3.3182e-04 - acc: 0.9756\n",
      "Epoch 78/100\n",
      "18099/18099 [==============================] - 4s 199us/sample - loss: 2.9155e-04 - acc: 0.9757\n",
      "Epoch 79/100\n",
      "18099/18099 [==============================] - 4s 197us/sample - loss: 2.9016e-04 - acc: 0.9756\n",
      "Epoch 80/100\n",
      "18099/18099 [==============================] - 4s 197us/sample - loss: 2.9408e-04 - acc: 0.9764\n",
      "Epoch 81/100\n",
      "18099/18099 [==============================] - 3s 191us/sample - loss: 2.9760e-04 - acc: 0.9735\n",
      "Epoch 82/100\n",
      "18099/18099 [==============================] - 3s 189us/sample - loss: 3.0329e-04 - acc: 0.9775\n",
      "Epoch 83/100\n",
      "18099/18099 [==============================] - 3s 189us/sample - loss: 2.8321e-04 - acc: 0.9741\n",
      "Epoch 84/100\n",
      "18099/18099 [==============================] - 4s 198us/sample - loss: 3.0431e-04 - acc: 0.9742\n",
      "Epoch 85/100\n",
      "18099/18099 [==============================] - 3s 193us/sample - loss: 3.0026e-04 - acc: 0.9762\n",
      "Epoch 86/100\n",
      "18099/18099 [==============================] - 3s 193us/sample - loss: 2.8950e-04 - acc: 0.9766\n",
      "Epoch 87/100\n",
      "18099/18099 [==============================] - 3s 190us/sample - loss: 2.9527e-04 - acc: 0.9755\n",
      "Epoch 88/100\n",
      "18099/18099 [==============================] - 3s 188us/sample - loss: 2.8793e-04 - acc: 0.9745\n",
      "Epoch 89/100\n",
      "18099/18099 [==============================] - 3s 193us/sample - loss: 2.9282e-04 - acc: 0.9740\n",
      "Epoch 90/100\n",
      "18099/18099 [==============================] - 4s 194us/sample - loss: 2.9286e-04 - acc: 0.9759\n",
      "Epoch 91/100\n",
      "18099/18099 [==============================] - 4s 195us/sample - loss: 2.8109e-04 - acc: 0.9760\n",
      "Epoch 92/100\n",
      "18099/18099 [==============================] - 3s 188us/sample - loss: 2.9876e-04 - acc: 0.9760\n",
      "Epoch 93/100\n",
      "18099/18099 [==============================] - 3s 189us/sample - loss: 2.9163e-04 - acc: 0.9765\n",
      "Epoch 94/100\n",
      "18099/18099 [==============================] - 3s 187us/sample - loss: 2.9783e-04 - acc: 0.9746\n",
      "Epoch 95/100\n",
      "18099/18099 [==============================] - 3s 189us/sample - loss: 2.8589e-04 - acc: 0.9765\n",
      "Epoch 96/100\n",
      "18099/18099 [==============================] - 3s 187us/sample - loss: 2.9504e-04 - acc: 0.9758\n",
      "Epoch 97/100\n",
      "18099/18099 [==============================] - 3s 187us/sample - loss: 2.9387e-04 - acc: 0.9754\n",
      "Epoch 98/100\n",
      "18099/18099 [==============================] - 3s 193us/sample - loss: 2.7991e-04 - acc: 0.9761\n",
      "Epoch 99/100\n",
      "18099/18099 [==============================] - 3s 188us/sample - loss: 2.9461e-04 - acc: 0.9760\n",
      "Epoch 100/100\n",
      "18099/18099 [==============================] - 3s 187us/sample - loss: 2.8036e-04 - acc: 0.9745\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 6, 120)            59040     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 6, 120)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 120)               115680    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 242       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 174,962\n",
      "Trainable params: 174,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gaurav\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 7.993899953892565e-05, Accuracy: 98.552405834198\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.callbacks import Callback\n",
    "#import keras.backend.tensorflow_backend as KTF\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "import  keras.callbacks\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    " \n",
    "def create_dataset(data,n_predictions,n_next):\n",
    "    '''\n",
    "         Process the data\n",
    "    '''\n",
    "    dim = data.shape[1]\n",
    "    train_X, train_Y = [], []\n",
    "    for i in range(data.shape[0]-n_predictions-n_next-1):\n",
    "        a = data[i:(i+n_predictions), :]\n",
    "        train_X.append(a)\n",
    "        tempb = data[(i+n_predictions):(i+n_predictions+n_next), :]\n",
    "        b = []\n",
    "        for j in range(len(tempb)):\n",
    "            for k in range(dim):\n",
    "                b.append(tempb[j, k])\n",
    "        train_Y.append(b)\n",
    "    train_X = np.array(train_X, dtype='float64')\n",
    "    train_Y = np.array(train_Y, dtype='float64')\n",
    " \n",
    "    test_X, test_Y = [], []\n",
    "    i = data.shape[0]-n_predictions-n_next-1\n",
    "    a = data[i:(i + n_predictions), :]\n",
    "    test_X.append(a)\n",
    "    tempb = data[(i + n_predictions):(i + n_predictions + n_next), :]\n",
    "    b = []\n",
    "    for j in range(len(tempb)):\n",
    "        for k in range(dim):\n",
    "            b.append(tempb[j, k])\n",
    "    test_Y.append(b)\n",
    "    test_X = np.array(test_X, dtype='float64')\n",
    "    test_Y = np.array(test_Y, dtype='float64')\n",
    " \n",
    "    return train_X, train_Y, test_X, test_Y\n",
    " \n",
    "def NormalizeMult(data, set_range):\n",
    "    '''\n",
    "         Return the normalized data and the maximum and minimum values\n",
    "    '''\n",
    "    normalize = np.arange(2*data.shape[1], dtype='float64')\n",
    "    normalize = normalize.reshape(data.shape[1], 2)\n",
    " \n",
    "    for i in range(0, data.shape[1]):\n",
    "        if set_range == True:\n",
    "            list = data[:, i]\n",
    "            listlow, listhigh = np.percentile(list, [0, 100])\n",
    "        else:\n",
    "            if i == 0:\n",
    "                listlow = -90\n",
    "                listhigh = 90\n",
    "            else:\n",
    "                listlow = -180\n",
    "                listhigh = 180\n",
    " \n",
    "        normalize[i, 0] = listlow\n",
    "        normalize[i, 1] = listhigh\n",
    " \n",
    "        delta = listhigh - listlow\n",
    "        if delta != 0:\n",
    "            for j in range(0, data.shape[0]):\n",
    "                data[j, i] = (data[j, i] - listlow)/delta\n",
    " \n",
    "    return data, normalize\n",
    " \n",
    "def trainModel(train_X, train_Y):\n",
    "    '''\n",
    "         trainX, trainY: the data needed to train the LSTM model\n",
    "    '''\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(\n",
    "        120,\n",
    "        input_shape=(train_X.shape[1], train_X.shape[2]),\n",
    "        return_sequences=True))\n",
    "    model.add(Dropout(0.3))\n",
    " \n",
    "    model.add(LSTM(\n",
    "        120,\n",
    "        return_sequences=False))\n",
    "    model.add(Dropout(0.3))\n",
    " \n",
    "    model.add(Dense(\n",
    "        train_Y.shape[1]))\n",
    "    model.add(Activation(\"relu\"))\n",
    " \n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['acc'])\n",
    "    model.fit(train_X, train_Y, epochs=50, batch_size=64, verbose=1)\n",
    "    model.summary()\n",
    " \n",
    "    return model\n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "    train_num = 6\n",
    "    per_num = 1\n",
    "    # set_range = False\n",
    "    set_range = True\n",
    " \n",
    "    # Read in time series file data\n",
    "    data = pd.read_csv(path+file).iloc[:, 0:2].values\n",
    "    print(\"Number of samples: {0}, dimension: {1}\".format(data.shape[0], data.shape[1]))\n",
    "    # print(data)\n",
    " \n",
    "    # Painting sample database\n",
    "    plt.scatter(data[:, 1], data[:, 0], c='b', marker='o', label='traj_A')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    " \n",
    "    #Normalized \n",
    "    data, normalize = NormalizeMult(data, set_range)\n",
    "    # print(normalize)\n",
    " \n",
    "    #Generate training data\n",
    "    train_X, train_Y, test_X, test_Y = create_dataset(data, train_num, per_num)\n",
    "    print(\"x\\n\", train_X.shape)\n",
    "    print(\"y\\n\", train_Y.shape)\n",
    " \n",
    "  \n",
    "    # Training model\n",
    "    model = trainModel(train_X, train_Y)\n",
    "    loss, acc = model.evaluate(train_X, train_Y, verbose=2)\n",
    "    print('Loss : {}, Accuracy: {}'.format(loss, acc * 100))\n",
    " \n",
    "    # Save model\n",
    "    np.save(\"./traj_model_trueNorm.npy\", normalize)\n",
    "    model.save(\"./traj_model_120.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f151dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Gaurav\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\Gaurav\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\Gaurav\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "listlow, listhigh, delta 1.0 19569.0 19568.0\n",
      "listlow, listhigh, delta -27.60317466 -10.29284478 17.31032988\n",
      "predict: [[ 1.97973561e+04 -1.09453059e+01]]\n",
      "true：[[ 1.95610000e+04 -1.09333982e+01]]\n",
      "Mean square error of prediction: 27932.102643164006\n",
      "Predicted straight-line distance: 13748.5745 KM\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD4CAYAAADsKpHdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAd/ElEQVR4nO3df3BV5b3v8fc3BEljAGsQRgm4vWNBDxh+BJU72jZIi7T2+uMACjcW72AnI+OMzO2UuXZQqa3MEecef9Ce1qEqoI2hFaTiqR5/JlI9kStYChHQC0ok6lxKUCTEyA+/94/1BHc2OyTs7GTvkM9rZs9e+3nWs/bzzY/13c9aaz/L3B0REZGcTHdARESygxKCiIgASggiIhIoIYiICKCEICIiQW6mO5CqQYMGeSwWy3Q3OuXgwYOcfvrpme5GWiiW7KRYslMmY9m4ceNedz8rWV2PTQixWIwNGzZkuhudUl1dTWlpaaa7kRaKJTspluyUyVjMrK6tOh0yEhERQAlBREQCJQQREQE6cA7BzB4DfgTscffRoWwM8DBQAOwCytz9czPrCzwCjA/bftzd/yW0KQGWA98AngPmububWT/gcaAEaABucPddqQRz+PBh6uvraW5uTqV5txs4cCDbtm3LaB/y8vIoKiqib9++Ge2HiGReR04qLwd+Q7TTbvEI8DN3f83M5gDzgTuBGUA/d7/IzPKBrWZWGXbwvwPKgTeJEsJU4HngZuBTdz/fzGYCi4EbUgmmvr6e/v37E4vFMLNUNtGtDhw4QP/+/TP2/u5OQ0MD9fX1nHfeeRnrh4hkh3YPGbn7OmBfQvFIYF1YfgmY1rI6cLqZ5RKNBA4Bn5vZ2cAAd6/xaDa9x4FrQ5trgBVheRUw2VLcmzc3N1NYWNh2MmhogM2bYcOG6LmhIZW3OWWYGYWFhT1mRCUiXSvVy05rgauBZ4hGBcNC+SqiHfwnQD7wP919n5lNAOrj2tcDQ8PyUGA3gLsfMbP9QCGwN/FNzaycaJTBkCFDqK6ublU/cOBAGhsbk/f4yJHoMXhw67JPP4XczFx9e/ToUQ4cOJCR947X3Nx83M/yZDU2NnZ6G9lCsWQnxdL1Ut0TzgGWmNldwFqikQDAJcBR4Bzgm8BfzexlINlH9pZ5t09U17rQfSmwFGDChAmeeB3vtm3b2j4Es3kzHDp0fPlpp0FxcfI2XSzTh4xa5OXlMW7cuE5tQ9eIZyfFkp2yNZaUEoK7bwemAJjZCOCqUPXfgf9w98PAHjN7A5gA/BUoittEEfBxWK4nGmHUh0NNAzn+EFXnJUsGJyoXEellUrrs1MwGh+cc4A6iK44APgSusMjpwERgu7t/Ahwws4nh/MBsosNNEI0wbgrL04FXvSvu2nPaaSdXnoLPPvuM3/72tyfd7oc//CGfffbZCddZs2YNZsb27dtT7J2IyIm1mxDMrBKoAUaaWb2Z3QzMMrP3gO1En/SXhdX/jehS1FrgLWCZu28OdXOJrk7aAewkusII4FGg0Mx2AD8Fbk9HYMcZOhRyWodb8UIhsatGkZMDsRhUVHTuLdpKCEePHj1hu+eee44zzjjjhOtUVlZy+eWXs3Llys50UUSkTe0eMnL3WW1UPZRk3Uaik8zJtrMBGJ2kvLmtNmlVWBg9f/QRHDpExUuDKV80jKYvolMYdXVQXh6tUlaW2lvcfvvt7Ny5k7Fjx9K3b18KCgo4++yz2bRpE1u3buXaa69l9+7dNDc3M2/ePGbNin60LfMyDRo0KOl2GxsbeeONN6iqquLqq6/mF7/4RWodFBE5gR47uV1KCguPJYYF06Hpi9bVTU2wYEHqCeHee++ltraWTZs2UV1dzVVXXUVtbe2xa/wfe+wxzjzzTL744gsuvvhipkyZ0qGTyn/+85+ZOnUqI0aM4Mwzz+Ttt99m/PjxqXVSRKQNvXbqig8/PLnyVFxyySWtvvC1ZMkSxowZw8SJE9m9ezc7d+7s0HYqKyuZOXMmADNnzqSysjJ9nRQRCXrXCCHO8OHRYaJk5ekSP995dXU1L7/8MjU1NeTn51NaWsqXX37Z7jYaGhp49dVXqa2txcw4evQoZsZ9993XI76NLSI9R68dISxaBPn5rcvy86PyVPXv37/NL5rt37+fb37zm+Tn57N9+3befPPNDm1z1apVzJ49m7q6Onbt2sXu3bs577zzeP3111PvqIhIEr02IZSVwdKlcO65YBY9L12a+vkDgMLCQi677DJGjx7N/PnzW9VNnTqVI0eOUFxczJ133snEiRNb1bf1ab+yspLrrruuVdm0adN48sknU++oiEgSvfaQEUQ7/84kgGTa2lH369eP559/vlXZgQMHjk1fMWDAgKTtkn29/bbbbut0P0VEEvXaEUK2GDVqFD/5yU80/bSIZFyvHiFkg5ZvHjc0NDB58uTj6l955RUKW75DISLShZQQskRhYSGbNm3KdDdEpBfTISMREQGUEEREJFBCEBERQAlBREQCJYQMaG86bBGRTOjdCaGiIroRQrpuiADs2rWLCy64gJtuuoni4mKmT59OU1MTsViMX/7yl1x++eU89dRTvPjii0yePJnx48czY8aMtu8FLSLSTXpvQqioiG6AUFcH7l/fECENSeHdd9+lvLyczZs3M2DAgGM3zcnLy+P111/ne9/7Hvfccw9r167l7bffZsKECdx///2dfl8Rkc7ovQlhwYLoBgjxWm6I0EnDhg3jsssuA+DGG288NhHdDTfcAMCbb77J1q1bmTJlCmPHjmXFihXUJZt6VUSkG/XeL6Z14Q0REieqa3ndMh22u/P973+fpUuXdugGOSIi3aH3jhDauvFBGm6I8OGHH1JTUwN8fS/keBMnTuSNN944doOcpqYm3nvvvU6/r4hIZ/TehNAVN0QILrzwQlasWEFxcTH79u1j7ty5rerPOussli9fzpw5cyguLmbixInH5jQSEcmU3nvIqGXe6wULosNEw4dHySAN82Hn5OTw8MMPtyrbtWtXq9dXXHEFr732mg4ZiUjW6L0JAbrmhggiIj1U7z1k1EVisRi1tbWZ7oaIyElTQhAREUAJQUREAiUEEREBlBBERCRQQugBHnzwQZoSp9kQEUkzJYQMONnpr0+UEDSVtoikS69OCBVbKog9GCPn7hxiD8ao2JJ9018vWbKEjz/+mEmTJjFp0iQACgoKuOuuu7j00kupqakhFouxd+9eADZs2EBpaSkABw8eZM6cOVx88cWMGzeOZ555ptPxicipq9cmhIotFZQ/W07d/jocp25/HeXPlqclKaRz+uvbbruNc845h6qqKqqqqoBoRz969GjWr19/3DxJ8RYtWsQVV1zBW2+9RVVVFfPnz+fgwYOdjk9ETk29NiEseGUBTYdbH4ZpOtzEgleyf/rrPn36MG3atHbXe/HFF7n33nsZO3YspaWlNDc382EaZnMVkVNTu1NXmNljwI+APe4+OpSNAR4GCoBdQJm7f25mZcD8uObFwHh332Rm1cDZwBehboq77zGzfsDjQAnQANzg7rvSENsJfbg/+Y6xrfKT0dXTX+fl5dGnT59jr3Nzc/nqq68AaG5uPlbu7qxevZqRI0ee9HuISO/TkRHCcmBqQtkjwO3ufhGwhpAE3L3C3ce6+1jgx8Aud98U166spd7d94Sym4FP3f184AFgcarBnIzhA5NPc91W+clI9/TX/fv358CBA23Wx2IxNm7cCMDq1auPlV955ZX8+te/xt0B+Nvf/pZaQCLSK7SbENx9HbAvoXgksC4svwQkO34xC6jsQB+uAVaE5VXAZEv8iN0FFk1eRH7f1tNf5/fNZ9Hk7Jv+ury8nB/84AfHTionWrhwIfPmzePb3/52q5HDnXfeyeHDhykuLmb06NHceeednY5NRE5d1vLp8YQrmcWAf487ZPSfwGJ3f8bMfgrc7e79E9rsBK5x99rwuhooBI4Cq4F73N3NrBaY6u71ce0udfe9SfpRDpQDDBkypGTlypWt6gcOHMj555/f4eD/tO1P3P363dQfqKeofxELL1/I9Rde3+H2ydTV1XH99dezfv36dtc9evRoqx14puzYsYP9+/d3ahuNjY0UFBSkqUeZpViyk2JJj0mTJm109wlJK9293QcQA2rjXl8AvAhsBBYCDQnrXwpsSSgbGp77h7azw+t3gKK49XYChe31qaSkxBNt3br1uLLu9sEHH/ioUaM6tO7nn3/exb3pmHT83KqqqjrfkSyhWLKTYkkPYIO3sV9N6X4I7r4dmAJgZiOAqxJWmUnC4SJ3/yg8HzCzJ4FLiE4m1wPDgHozywUGcvwhqh6jM9NfX3fddXzwwQetyhYvXsyVV16Zjq6JiJxQSgnBzAZ7dIVQDnAH0RVHLXU5wAzgO3FlucAZ7r7XzPoSXbX0cqheC9wE1ADTgVdDFut11qxZk+kuiEgv1pHLTiuBUmCQmdUTHSIqMLNbwypPA8vimnwHqHf39+PK+gEvhGTQhygZ/D7UPQo8YWY7iEYGM1MPJzoE1g3npE8ZvTT3ikgS7SYEd5/VRtVDbaxfDUxMKDtI9D2DZOs3E40oOi0vL4+GhgYKCwuVFDrA3WloaCAvLy/TXRGRLHBK3VO5qKiI+vp6/vGPf2S6Kx3S3Nyc8Z1xXl4eRUVFGe2DiGSHUyoh9O3bl/POOy/T3eiw6upqxo0bl+luiIgAvXguIxERaU0JQUREACUEEREJlBBERARQQhARkUAJQUREACUEEREJlBBERARQQhARkUAJQUREACUEEREJlBBERARQQhARkUAJQUREACUEEREJlBBERARQQhARkUAJQUREACUEEREJlBBERARQQhARkUAJQUREACUEEREJlBBERARQQhARkUAJQUREACUEEREJlBBERARQQhARkaDdhGBmj5nZHjOrjSsbY2Y1ZrbFzJ41swGhvMzMNsU9vjKzsaGuJKy/w8yWmJmF8n5m9sdQvt7MYl0TqoiInEhHRgjLgakJZY8At7v7RcAaYD6Au1e4+1h3Hwv8GNjl7ptCm98B5cC3wqNlmzcDn7r7+cADwOJUgxERkdS1mxDcfR2wL6F4JLAuLL8ETEvSdBZQCWBmZwMD3L3G3R14HLg2rHcNsCIsrwImt4weRESk+6R6DqEWuDoszwCGJVnnBkJCAIYC9XF19aGspW43gLsfAfYDhSn2S0REUpSbYrs5wBIzuwtYCxyKrzSzS4Emd28575DsE793oK4VMysnOuzEkCFDqK6uPvmeZ5HGxsYeH0MLxZKdFEt2ytZYUkoI7r4dmAJgZiOAqxJWmcnXowOIRgRFca+LgI/j6oYB9WaWCwzk+ENULe+7FFgKMGHCBC8tLU2l+1mjurqanh5DC8WSnRRLdsrWWFI6ZGRmg8NzDnAH8HBcXQ7RYaSVLWXu/glwwMwmhvMDs4FnQvVa4KawPB14NZxnEBGRbtTuCMHMKoFSYJCZ1QMLgQIzuzWs8jSwLK7Jd4B6d38/YVNzia5Y+gbwfHgAPAo8YWY7iEYGM1OKREREOqXdhODus9qoeqiN9auBiUnKNwCjk5Q3E40oREQkg/RNZRERAZQQREQkUEIQERFACUFERAIlBBERAZQQREQkUEIQERFACUFERAIlBBERAZQQREQkUEIQERFACUFERAIlBBERAZQQREQkUEIQERFACUFERAIlBBERAZQQREQkUEIQERFACUFERAIlBBERAZQQREQkUEIQERFACUFERAIlBBERAZQQREQkUEIQERFACUFERAIlBBERAZQQREQkUEIQERFACUFERIJ2E4KZPWZme8ysNq5sjJnVmNkWM3vWzAbE1RWHundCfV4orzazd81sU3gMDuX9zOyPZrbDzNabWawL4hQRkXZ0ZISwHJiaUPYIcLu7XwSsAeYDmFku8AfgFncfBZQCh+Palbn72PDYE8puBj519/OBB4DFKcYiIiKd0G5CcPd1wL6E4pHAurD8EjAtLE8BNrv730PbBnc/2s5bXAOsCMurgMlmZh3ou4iIpFFuiu1qgauBZ4AZwLBQPgJwM3sBOAtY6e73xbVbZmZHgdXAPe7uwFBgN4C7HzGz/UAhsDfxTc2sHCgHGDJkCNXV1Sl2Pzs0Njb2+BhaKJbspFiyU9bG4u7tPoAYUBv3+gLgRWAjsBBoCOU/Az4ABgH5QA0wOdQNDc/9Q9vZ4fU7QFHctncChe31qaSkxHu6qqqqTHchbRRLdlIs2SmTsQAbvI39akpXGbn7dnef4u4lQGXYiQPUA6+5+153bwKeA8aHNh+F5wPAk8AlcW2GwbFzEAM5/hCViIh0sZQSQtwVQjnAHcDDoeoFoNjM8sPO/bvAVjPLNbNBoU1f4EdEh50A1gI3heXpwKshi4mISDdq9xyCmVUSXS00yMzqiQ4RFZjZrWGVp4FlAO7+qZndD7wFOPCcu//FzE4HXgjJoA/wMvD70P5R4Akz20E0MpiZruBERKTj2k0I7j6rjaqH2lj/D0SXnsaXHQRK2li/mejEtIiIZJC+qSwiIoASgoiIBEoIIiICKCGIiEighCAiIoASgoiIBEoIIiICKCGIiEighCAiIoASgoiIBEoIIiICKCGIiEighCAiIoASgoiIBEoIIiICKCGIiEighCAiIoASgoiIBEoIIiICKCGIiEighCAiIoASgoiIBEoIIiICKCGIiEighCAiIoASgoiIBEoIIiICKCGIiEighCAiIoASgoiIBEoIIiICKCGIiEjQbkIws8fMbI+Z1caVjTGzGjPbYmbPmtmAuLriUPdOqM8L5SXh9Q4zW2JmFsr7mdkfQ/l6M4t1QZwiItKOjowQlgNTE8oeAW5394uANcB8ADPLBf4A3OLuo4BS4HBo8zugHPhWeLRs82bgU3c/H3gAWJxiLCIi0gntJgR3XwfsSygeCawLyy8B08LyFGCzu/89tG1w96NmdjYwwN1r3N2Bx4FrQ5trgBVheRUwuWX0ICIi3Sc3xXa1wNXAM8AMYFgoHwG4mb0AnAWsdPf7gKFAfVz7+lBGeN4N4O5HzGw/UAjsTXxTMysnGmUwZMgQqqurU+x+dmhsbOzxMbRQLNlJsWSnbI0l1YQwB1hiZncBa4FDcdu7HLgYaAJeMbONwOdJtuHhOdlowJOU4e5LgaUAEyZM8NLS0hS7nx2qq6vp6TG0UCzZSbFkp2yNJaWrjNx9u7tPcfcSoBLYGarqgdfcfa+7NwHPAeNDeVHcJoqAj+PaDINj5yAGcvwhKhER6WIpJQQzGxyec4A7gIdD1QtAsZnlh537d4Gt7v4JcMDMJobzA7OJDjdBNMK4KSxPB14N5xlERKQbtXvIyMwqia4WGmRm9cBCoMDMbg2rPA0sA3D3T83sfuAtosM+z7n7X8J6c4muWPoG8Hx4ADwKPGFmO4hGBjM7H5aIiJysdhOCu89qo+qhNtb/A9Glp4nlG4DRScqbiU5Mi4hIBumbyiIiAighiIhIoIQgIiKAEoKIiARKCCIiAighiIhIoIQgIiKAEoKIiARKCCIiAighiIhIoIQgIiKAEoKIiARKCCIiAighiIhIoIQgIiKAEoKIiARKCCIiAighiIhIoIQgIiKAEoKIiARKCCIiAighiIhIoIQgIiKAEoKISI9RsaWC2IMxcu7OIfZgjIotFWndfm5atyYiIl2iYksFc9aUc8ibAKjbX8ecNeUAlF1Ulpb30AhBRCRLVVRALAY5OTB7+YJjyaDFIW9i3toFaXs/JYQeIv4PIxaLXovIqauiAsrLoa4O3OGr/h8mXa/hcPLyVOiQUQ9QUQFz5sChQ9HrurroNUBZekaKIpJlFiyApvgBwf7hcEbd8SvuH56299QIIYu1jApuvPHrZNDi0CGYNy8j3RKRbvBh4gf/VxbBofzWZYfyo/I0UULIUvHDxbY0NHRff0Skew1P/OC/pQyeXQqfnQtu0fOzSyn8OH2HCXTIKEsdN1wUkV5l0aLoQ2Gr/cCWsugR9O0LDy1L33tqhJCljhsuJlFY2PX9EJHMKCuDpUvh3HPBLHqeO7f162XL0nsesd0Rgpk9BvwI2OPuo0PZGOBhoADYBZS5++dmFgO2Ae+G5m+6+y2hTTVwNvBFqJvi7nvMrB/wOFACNAA3uPuudATXkw0ffuLDRX37wkMPdV9/RKT7lZV174UjHRkhLAemJpQ9Atzu7hcBa4D5cXU73X1seNyS0K4srm5PKLsZ+NTdzwceABafdBSnoEWLID/h/JFZ9NwVnwxERNpNCO6+DtiXUDwSWBeWXwKmdaIP1wArwvIqYLJZy66v90o2XHziieh65F27lAxEJP3M3dtfKToU9O9xh4z+E1js7s+Y2U+Bu929f1jvHeA94HPgDnf/a2hTDRQCR4HVwD3u7mZWC0x19/qw3k7gUnffm6Qf5UA5wJAhQ0pWrlzZmdgzrrGxkYKCgkx3Iy0US3ZSLNkpk7FMmjRpo7tPSFrp7u0+gBhQG/f6AuBFYCOwEGgI5f2AwrBcAuwGBoTXQ8Nz/9B2dnj9DlAUt+2dLds40aOkpMR7uqqqqkx3IW0US3ZSLNkpk7EAG7yN/WpKVxm5+3Z3n+LuJUBl2Inj7l+6e0NY3hjKR4TXH4XnA8CTwCVhc/XAMAAzywUGcvwhKhER6WIpJQQzGxyec4A7iK44wszOMrM+Yfm/AN8C3jezXDMbFMr7El21VBs2txa4KSxPB14NWUxERLpRRy47rQRKgUFmVk90iKjAzG4NqzwNtHw14jvAL83sCNG5glvcfZ+ZnQ68EJJBH+Bl4PehzaPAE2a2g2hkMDMtkYmIyElpNyG4+6w2qo67Ct7dVxOdME4sP0h0TiHZ9puBGe31Q0REulaHrjLKRmb2D+AEX93qEQYBx11N1UMpluykWLJTJmM5193PSlbRYxPCqcDMNnhbl3/1MIolOymW7JStsWguIxERAZQQREQkUELIrKWZ7kAaKZbspFiyU1bGonMIIiICaIQgIiKBEoKIiABKCGlhZjPM7B0z+8rMJiTU/dzMdpjZu2Z2ZRvtx5hZjZltMbNnzWxAQv1wM2s0s58labs2zBjbI2Mxs3wz+4uZbQ/ve29PjSWUlYT1d5jZknRN5d5VsZjZJWa2KTz+bmbXxbWZFdbfbGb/0TL9TA+O5zQzW2pm74W/t85M25/RWOLapvX/v0OznerR7mywFxLdI6IamBBX/k/A34lmgT2PaLK/PknavwV8NyzPAX6VUL8aeAr4WUL5PxNNFFjbU2MB8oFJYfk04K/AD3piLKHs/wD/FTDg+WyPJfz8c8Py2cAeohkMcsPyoFB3H/CLbP87ayue8Ppuomn3IfowPKinxhLK0v7/rxFCGrj7Nnd/N0nVNcBKj2aB/QDYwdezvMZr84ZDZnYt8D7RNOHElRcAPwXu6XQAcbo7FndvcveqsHwIeBsoSkMo3R6LmZ1NNN17jUf/sY8D16YhlC6LJfz8j4TyPKDlKhMLj9PDKGcA8HE6Ygnv293xQLSz/Zew3lee5J4rqchELF31/6+E0LWGEt0TokV9KEtUC1wdlmfw9XTgpwP/i+iTTaJfAf8KNKWrs+3oylgI65wB/Dfglc5394S6KpahYVvtbTedOhULgJldambvAFuIJqQ84u6Hgbmh7GOiT7uPpr/7x+mSeMLfFsCvzOxtM3vKzIakvfetdUksoapL/v+VEDrIzF42s9okj2tO1CxJWbLrfOcAt5rZRqIbCB0K5XcDD7h7Y0JfxgLnu/uak48ku2KJ61Mu0b01lrj7+z00lo5uN3mnMhML7r7e3UcBFwM/N7M8i2YmnguMA84BNgM/72gs2RYP0SGwIuANdx8P1AD/uyfG0tn//xNpd7ZTibj791JoduzmP0ERSYbd7r4dmAJgZiOAq0LVpcB0M7sPOAP4ysyaiaYWLzGzXUS/w8FmVu3upT0tFnf/TahfCvxfd3/wZDqVTbEQnVOIP9yVdLttyVAs8etsM7ODwGjCzszdd4Y2fwJuP5mOZVk8G4k+TbfsRJ8Cbu5op7IslovpxP//CaXrZIQeDsefVBpF65NK75P8pNLg8JxDdNx5TpJ1fkHCSeVQHiONJ5UyEQvRcdDVQE5P/70QnSCcyNcnlX+YzbGENi0nLs8l2mENIhoVfAKcFep+Bfxrtv9u2oonvF4JXBGW/wfwVE+NJa5tjHReVJLuX3BvfADXEX0a+BL4f8ALcXULiK4ueJe4K06AR1r+eIB5wHvhcS/hG+QJ79Fqx9NlfxDdHAvRpyYHtgGbwuMnPTGW8HoC0THhncBvkrXJpliAHxOdGN9EdEL/2rj2t4Tfy2bgWTpwr/Msj+dcopO3m4nOUw3vqbHEbSdGGv//NXWFiIgAOqksIiKBEoKIiABKCCIiEighiIgIoIQgIiKBEoKIiABKCCIiEvx/X1disisaS7EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())\n",
    "def mse(predictions, targets):\n",
    "    return ((predictions - targets) ** 2).mean()\n",
    " \n",
    "def reshape_y_hat(y_hat,dim):\n",
    "    re_y = []\n",
    "    i = 0\n",
    "    while i < len(y_hat):\n",
    "        tmp = []\n",
    "        for j in range(dim):\n",
    "            tmp.append(y_hat[i+j])\n",
    "        i = i + dim\n",
    "        re_y.append(tmp)\n",
    "    re_y = np.array(re_y, dtype='float64')\n",
    "    return re_y\n",
    " \n",
    " #Multidimensional denormalization\n",
    "def FNormalizeMult(data,normalize):\n",
    " \n",
    "    data = np.array(data, dtype='float64')\n",
    "         #Column\n",
    "    for i in range(0, data.shape[1]):\n",
    "        listlow = normalize[i, 0]\n",
    "        listhigh = normalize[i, 1]\n",
    "        delta = listhigh - listlow\n",
    "        print(\"listlow, listhigh, delta\", listlow, listhigh, delta)\n",
    "                 #Row \n",
    "        if delta != 0:\n",
    "            for j in range(0, data.shape[0]):\n",
    "                data[j, i] = data[j, i]*delta + listlow\n",
    " \n",
    "    return data\n",
    " \n",
    " #Using normalization of training data\n",
    "def NormalizeMultUseData(data,normalize):\n",
    " \n",
    "    for i in range(0, data.shape[1]):\n",
    " \n",
    "        listlow = normalize[i, 0]\n",
    "        listhigh = normalize[i, 1]\n",
    "        delta = listhigh - listlow\n",
    " \n",
    "        if delta != 0:\n",
    "            for j in range(0, data.shape[0]):\n",
    "                data[j, i] = (data[j, i] - listlow)/delta\n",
    " \n",
    "    return data\n",
    " \n",
    "from math import sin, asin, cos, radians, fabs, sqrt\n",
    "EARTH_RADIUS = 6371 # The average radius of the earth, 6371km\n",
    " \n",
    " # Calculate the straight-line distance between two latitude and longitude\n",
    "def hav(theta):\n",
    "    s = sin(theta / 2)\n",
    "    return s * s\n",
    "def get_distance_hav(lat0, lng0, lat1, lng1):\n",
    "    # \"Use the haversine formula to calculate the distance between two points on the sphere.\"\n",
    "    # Longitude and latitude converted to radians\n",
    "    lat0 = radians(lat0)\n",
    "    lat1 = radians(lat1)\n",
    "    lng0 = radians(lng0)\n",
    "    lng1 = radians(lng1)\n",
    " \n",
    "    dlng = fabs(lng0 - lng1)\n",
    "    dlat = fabs(lat0 - lat1)\n",
    "    h = hav(dlat) + cos(lat0) * cos(lat1) * hav(dlng)\n",
    "    distance = 2 * EARTH_RADIUS * asin(sqrt(h))\n",
    "    return distance\n",
    " \n",
    "if __name__ == '__main__':\n",
    "    test_num = 6\n",
    "    per_num = 1\n",
    "    data_all = pd.read_csv(path+file).iloc[-2*(test_num+per_num):-1*(test_num+per_num), 0:2].values\n",
    "    data_all.dtype = 'float64'\n",
    " \n",
    "    data = copy.deepcopy(data_all[:-per_num, :])\n",
    "    y = data_all[-per_num:, :]\n",
    "  \n",
    "    # #Normalized \n",
    "    normalize = np.load(\"./traj_model_trueNorm.npy\")\n",
    "    data = NormalizeMultUseData(data, normalize)\n",
    " \n",
    "    model = load_model(\"./traj_model_120.h5\")\n",
    "    test_X = data.reshape(1, data.shape[0], data.shape[1])\n",
    "    y_hat = model.predict(test_X)\n",
    "    y_hat = y_hat.reshape(y_hat.shape[1])\n",
    "    y_hat = reshape_y_hat(y_hat, 2)\n",
    " \n",
    "    #Antinormalization\n",
    "    y_hat = FNormalizeMult(y_hat, normalize)\n",
    "    print(\"predict: {0}\\ntrue：{1}\".format(y_hat, y))\n",
    "    print('Mean square error of prediction:', mse(y_hat, y))\n",
    "    print('Predicted straight-line distance: {:.4f} KM'.format(get_distance_hav(y_hat[0, 0], y_hat[0, 1], y[0, 0], y[0, 1])))\n",
    " \n",
    "   \n",
    "    # Draw test sample database\n",
    "    p1 = plt.scatter(data_all[:-per_num, 1], data_all[:-per_num, 0], c='b', marker='o', label='traj_A')\n",
    "    p2 = plt.scatter(y_hat[:, 1], y_hat[:, 0], c='r', marker='o', label='pre')\n",
    "    p3 = plt.scatter(y[:, 1], y[:, 0], c='g', marker='o', label='pre_true')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c95662d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
